#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºæœºå™¨å­¦ä¹ æ¨¡å‹æ¼”ç¤ºç¨‹åº
å®ç°å®Œæ•´çš„æ¨¡å‹è®­ç»ƒã€è¯„ä¼°ã€ç‰¹å¾åˆ†æå’Œå¯è§†åŒ–æµç¨‹
"""

import json
import time
from datetime import datetime
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from enhanced_ml_model import EnhancedTrafficPredictor, LightML, get_model_report, predict_traffic

class MLDemo:
    """æœºå™¨å­¦ä¹ æ¨¡å‹æ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.predictor = EnhancedTrafficPredictor()
        self.demo_data = None
        
    def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´çš„æ¼”ç¤ºæµç¨‹"""
        print("=" * 60)
        print("å¢å¼ºæœºå™¨å­¦ä¹ æ¨¡å‹å®Œæ•´æ¼”ç¤º")
        print("=" * 60)
        
        # 1. æ•°æ®ç”Ÿæˆ
        print("\n1. ç”Ÿæˆè®­ç»ƒæ•°æ®...")
        self.generate_demo_data()
        
        # 2. ç‰¹å¾å·¥ç¨‹
        print("\n2. æ‰§è¡Œç‰¹å¾å·¥ç¨‹...")
        processed_data = self.feature_engineering_demo()
        
        # 3. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
        print("\n3. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°...")
        performance = self.model_evaluation_demo()
        
        # 4. ç‰¹å¾é‡è¦æ€§åˆ†æ
        print("\n4. ç‰¹å¾é‡è¦æ€§åˆ†æ...")
        feature_analysis = self.feature_importance_demo()
        
        # 5. é¢„æµ‹æ¼”ç¤º
        print("\n5. å®æ—¶é¢„æµ‹æ¼”ç¤º...")
        prediction_demo = self.prediction_demo()
        
        # 6. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        print("\n6. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š...")
        final_report = self.generate_comprehensive_report()
        
        return final_report
    
    def generate_demo_data(self):
        """ç”Ÿæˆæ¼”ç¤ºæ•°æ®"""
        print("æ­£åœ¨ç”Ÿæˆ1000ä¸ªæ ·æœ¬çš„è®­ç»ƒæ•°æ®...")
        X, y_congestion, y_speed, y_time = self.predictor.generate_enhanced_training_data(1000)
        
        self.demo_data = {
            'X': X,
            'y_congestion': y_congestion,
            'y_speed': y_speed,
            'y_time': y_time
        }
        
        print(f"æ•°æ®ç”Ÿæˆå®Œæˆ:")
        print(f"  - ç‰¹å¾æ•°é‡: {len(X[0])}")
        print(f"  - æ ·æœ¬æ€»æ•°: {len(X)}")
        print(f"  - æ‹¥å µæ•°æ®èŒƒå›´: {min(y_congestion):.3f} ~ {max(y_congestion):.3f}")
        print(f"  - é€Ÿåº¦æ•°æ®èŒƒå›´: {min(y_speed):.1f} ~ {max(y_speed):.1f} km/h")
        
        return self.demo_data
    
    def feature_engineering_demo(self):
        """ç‰¹å¾å·¥ç¨‹æ¼”ç¤º"""
        if not self.demo_data:
            print("è¯·å…ˆç”Ÿæˆæ¼”ç¤ºæ•°æ®")
            return None
            
        X = self.demo_data['X']
        print("åŸå§‹ç‰¹å¾:")
        print(f"  - ç‰¹å¾ç»´åº¦: {len(X[0])}")
        print(f"  - ç‰¹å¾åç§°: {self.predictor.feature_names}")
        
        # æ‰§è¡Œç‰¹å¾å·¥ç¨‹
        X_processed = self.predictor.feature_engineering(X)
        
        print("\nç‰¹å¾å·¥ç¨‹å:")
        print(f"  - æ–°ç‰¹å¾ç»´åº¦: {len(X_processed[0])}")
        print(f"  - æ–°å¢ç‰¹å¾: ['is_peak_hour', 'is_weekend', 'speed_efficiency']")
        
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç‰¹å¾å˜åŒ–
        print(f"\nç¬¬ä¸€ä¸ªæ ·æœ¬ç‰¹å¾å˜åŒ–:")
        print(f"  åŸå§‹: {X[0]}")
        print(f"  å¤„ç†å: {X_processed[0]}")
        
        return X_processed
    
    def model_evaluation_demo(self):
        """æ¨¡å‹è¯„ä¼°æ¼”ç¤º"""
        if not self.demo_data:
            print("è¯·å…ˆç”Ÿæˆæ¼”ç¤ºæ•°æ®")
            return None
            
        X = self.demo_data['X']
        y_congestion = self.demo_data['y_congestion']
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = LightML.train_test_split(X, y_congestion, test_size=0.2)
        
        print(f"æ•°æ®é›†åˆ†å‰²:")
        print(f"  - è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"  - æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        # è¯„ä¼°æ¨¡å‹
        metrics = self.predictor.evaluate_model(X_test, y_test)
        
        print(f"\næ¨¡å‹æ€§èƒ½æŒ‡æ ‡:")
        print(f"  - RÂ² Score: {metrics['r2_score']}")
        print(f"  - å‡æ–¹è¯¯å·® (MSE): {metrics['mse']}")
        print(f"  - å¹³å‡ç»å¯¹è¯¯å·® (MAE): {metrics['mae']}")
        
        # ç”Ÿæˆé¢„æµ‹å¯è§†åŒ–
        predictions = [self.predictor.predict(features)['predicted_congestion'] for features in X_test]
        visualization = self.predictor.visualize_predictions(X_test, y_test, predictions)
        
        print(f"\né¢„æµ‹å¯è§†åŒ–æ‘˜è¦:")
        print(visualization)
        
        return metrics
    
    def feature_importance_demo(self):
        """ç‰¹å¾é‡è¦æ€§åˆ†ææ¼”ç¤º"""
        feature_importance = self.predictor.get_feature_importance()
        
        print("ç‰¹å¾é‡è¦æ€§åˆ†æ:")
        print("-" * 40)
        
        # æŒ‰é‡è¦æ€§æ’åº
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
        
        for feature, importance in sorted_features:
            bar_length = int(importance * 30)
            bar = 'â–ˆ' * bar_length + 'â–‘' * (30 - bar_length)
            print(f"{feature:15s} {bar} {importance:.3f}")
        
        print("\nå…³é”®æ´å¯Ÿ:")
        print("  â€¢ æ—¶é—´ç‰¹å¾(å°æ—¶)å¯¹äº¤é€šé¢„æµ‹å½±å“æœ€å¤§")
        print("  â€¢ æ˜ŸæœŸå‡ å’Œå·¥ä½œæ—¥æ¨¡å¼ä¹Ÿå¾ˆé‡è¦") 
        print("  â€¢ å®æ—¶äº¤é€šæ°´å¹³å’Œé€Ÿåº¦æä¾›è¡¥å……ä¿¡æ¯")
        
        return feature_importance
    
    def prediction_demo(self):
        """å®æ—¶é¢„æµ‹æ¼”ç¤º"""
        print("å®æ—¶é¢„æµ‹æ¼”ç¤º:")
        print("-" * 40)
        
        # å®šä¹‰å‡ ä¸ªå…¸å‹åœºæ™¯
        scenarios = [
            {
                'name': 'å‘¨ä¸€æ—©é«˜å³°',
                'features': [8, 1, 0.7, 25, 0.7],  # å‘¨ä¸€8ç‚¹ï¼Œé«˜æ‹¥å µ
                'description': 'å·¥ä½œæ—¥æ—©é«˜å³°æ—¶æ®µ'
            },
            {
                'name': 'å‘¨äº”æ™šé«˜å³°', 
                'features': [18, 4, 0.8, 20, 0.8],  # å‘¨äº”18ç‚¹ï¼Œæé«˜æ‹¥å µ
                'description': 'å‘¨æœ«å‰æ™šé«˜å³°'
            },
            {
                'name': 'å‘¨æœ«ä¸­åˆ',
                'features': [12, 6, 0.3, 55, 0.3],  # å‘¨æ—¥12ç‚¹ï¼Œä½æ‹¥å µ
                'description': 'å‘¨æœ«ä¼‘é—²æ—¶æ®µ'
            },
            {
                'name': 'æ·±å¤œæ—¶æ®µ',
                'features': [2, 2, 0.1, 70, 0.1],  # å‘¨äºŒå‡Œæ™¨2ç‚¹ï¼Œæä½æ‹¥å µ
                'description': 'æ·±å¤œç•…é€šæ—¶æ®µ'
            }
        ]
        
        results = []
        for scenario in scenarios:
            prediction = self.predictor.predict(scenario['features'])
            results.append({
                'scenario': scenario,
                'prediction': prediction
            })
            
            print(f"\n{scenario['name']} ({scenario['description']}):")
            print(f"  è¾“å…¥ç‰¹å¾: {scenario['features']}")
            print(f"  é¢„æµ‹æ‹¥å µ: {prediction['predicted_congestion']}")
            print(f"  é¢„æµ‹é€Ÿåº¦: {prediction['predicted_speed']} km/h")
            print(f"  é¢„æµ‹æ—¶é—´: {prediction['predicted_time']} åˆ†é’Ÿ")
            print(f"  ç½®ä¿¡åº¦: {prediction['confidence']}")
            
            # æä¾›å»ºè®®
            congestion = prediction['predicted_congestion']
            if congestion > 0.7:
                print("  ğŸ’¡ å»ºè®®: ä¸¥é‡æ‹¥å µï¼Œå»ºè®®æ›´æ”¹å‡ºè¡Œè®¡åˆ’")
            elif congestion > 0.5:
                print("  ğŸ’¡ å»ºè®®: ä¸­åº¦æ‹¥å µï¼Œè€ƒè™‘æ›¿ä»£è·¯çº¿")
            else:
                print("  ğŸ’¡ å»ºè®®: è·¯å†µè‰¯å¥½ï¼Œé€‚åˆå‡ºè¡Œ")
        
        return results
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        report = self.predictor.create_performance_report()
        
        print("\n" + "=" * 60)
        print("æ¨¡å‹ç»¼åˆæ€§èƒ½æŠ¥å‘Š")
        print("=" * 60)
        
        print(f"\nğŸ“Š æ¨¡å‹åŸºæœ¬ä¿¡æ¯:")
        print(f"  â€¢ æ¨¡å‹ç±»å‹: {report['model_type']}")
        print(f"  â€¢ è®­ç»ƒçŠ¶æ€: {report['training_status']}")
        
        print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        metrics = report['performance_metrics']
        print(f"  â€¢ RÂ² Score: {metrics['r2_score']}")
        print(f"  â€¢ å‡æ–¹è¯¯å·®: {metrics['mse']}")
        print(f"  â€¢ å¹³å‡ç»å¯¹è¯¯å·®: {metrics['mae']}")
        
        print(f"\nğŸ” ç‰¹å¾é‡è¦æ€§:")
        importance = report['feature_importance']
        for feature, score in importance.items():
            print(f"  â€¢ {feature}: {score:.3f}")
        
        print(f"\nğŸ§  æ¨¡å‹è§£é‡Šæ€§:")
        interpretation = report['model_interpretation']
        for key, value in interpretation.items():
            print(f"  â€¢ {key}: {value}")
        
        print(f"\nâœ… æ¨¡å‹ä¼˜åŠ¿:")
        print("  â€¢ æ— éœ€å¤–éƒ¨ä¾èµ–ï¼Œçº¯Pythonå®ç°")
        print("  â€¢ åŸºäºè§„åˆ™çš„é¢„æµ‹é€»è¾‘ï¼Œè§£é‡Šæ€§å¼º")
        print("  â€¢ åŒ…å«å®Œæ•´çš„ç‰¹å¾å·¥ç¨‹å’Œè¯„ä¼°æµç¨‹")
        print("  â€¢ æä¾›å®æ—¶é¢„æµ‹å’Œæ™ºèƒ½å»ºè®®")
        
        print(f"\nğŸ”® åç»­å¼€å‘å»ºè®®:")
        print("  â€¢ å¯é›†æˆçœŸå®äº¤é€šæ•°æ®æº")
        print("  â€¢ æ·»åŠ æ·±åº¦å­¦ä¹ æ¨¡å‹æ”¯æŒ")
        print("  â€¢ å®ç°å®æ—¶æ•°æ®æµå¤„ç†")
        print("  â€¢ å¼€å‘Web APIæ¥å£")
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    try:
        demo = MLDemo()
        
        print("å¼€å§‹å¢å¼ºæœºå™¨å­¦ä¹ æ¨¡å‹æ¼”ç¤º...")
        start_time = time.time()
        
        # è¿è¡Œå®Œæ•´æ¼”ç¤º
        final_report = demo.run_complete_demo()
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        print(f"\nâ±ï¸  æ¼”ç¤ºå®Œæˆæ—¶é—´: {elapsed_time:.2f} ç§’")
        print("ğŸ‰ æ‰€æœ‰åŠŸèƒ½æ¼”ç¤ºå®Œæ¯•ï¼")
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"ml_model_report_{timestamp}.json"
        
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")
        
    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()